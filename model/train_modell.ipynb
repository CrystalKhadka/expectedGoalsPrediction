{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-14T02:48:59.878071Z",
     "start_time": "2025-02-14T02:48:52.636267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/visualizations/combined_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "data.columns = data.columns.str.strip().str.lower()\n",
    "\n",
    "# Ensure round is numeric\n",
    "data['round'] = data['round'].str.extract('(\\\\d+)').astype(int)\n",
    "\n",
    "# Group by 'round' and calculate aggregate statistics\n",
    "grouped_data = data.groupby('round').agg({\n",
    "    'round': 'first',\n",
    "    'expected goals': 'mean',\n",
    "    'venue': 'first',\n",
    "    'opponent': 'first',\n",
    "    'goals': 'mean',\n",
    "    'shots': 'mean',\n",
    "    'touches': 'mean',\n",
    "    'ast': 'mean',\n",
    "    'passcmp': 'mean',\n",
    "    'passcmp%': 'mean',\n",
    "    'min': 'mean',\n",
    "    'formation': 'first',\n",
    "    'opp formation': 'first',\n",
    "    'poss': 'mean',\n",
    "    'gca': 'mean',\n",
    "    'sca': 'mean',\n",
    "    'gls': 'mean',\n",
    "    'sh': 'mean'\n",
    "})\n",
    "\n",
    "# Add rolling and cumulative features (excluding the current match)\n",
    "rolling_window = 5\n",
    "\n",
    "# Team-level rolling and cumulative features\n",
    "team_rolling_features = ['expected goals', 'goals', 'shots', 'touches', 'poss', 'gca', 'sca']\n",
    "for feature in team_rolling_features:\n",
    "    grouped_data[f'rolling_{feature}'] = grouped_data[feature].shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    "    grouped_data[f'cumulative_{feature}'] = grouped_data[feature].shift(1).expanding().mean()\n",
    "\n",
    "# Player-level rolling and cumulative features for Haaland\n",
    "haaland_features = ['gls', 'ast', 'sh', 'min', 'touches', 'poss', 'gca', 'sca']\n",
    "for feature in haaland_features:\n",
    "    grouped_data[f'rolling_haaland_{feature}'] = grouped_data[feature].shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    "    grouped_data[f'cumulative_haaland_{feature}'] = grouped_data[feature].shift(1).expanding().mean()\n",
    "\n",
    "# Add Haaland's performance rating\n",
    "# Performance Rating Formula: (Goals * 4 + Assists * 3 + xG Contribution) / Minutes Played\n",
    "grouped_data['haaland_performance_rating'] = (\n",
    "    grouped_data['gls'] * 4 + grouped_data['ast'] * 3 + grouped_data['expected goals']\n",
    ") / grouped_data['min'].replace(0, 1)  # Replace 0 minutes to avoid division by zero\n",
    "\n",
    "# Add rolling and cumulative ratings (excluding current match)\n",
    "grouped_data['rolling_haaland_rating'] = grouped_data['haaland_performance_rating'].shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    "grouped_data['cumulative_haaland_rating'] = grouped_data['haaland_performance_rating'].shift(1).expanding().mean()\n",
    "\n",
    "# Define the parse_formation function\n",
    "def parse_formation(formation):\n",
    "    parts = str(formation).split('-')\n",
    "    if len(parts) == 3:\n",
    "        return [int(part) for part in parts]\n",
    "    elif len(parts) == 4:\n",
    "        parts[1] = int(parts[1]) + int(parts[2])\n",
    "        parts[2] = parts[3]\n",
    "        return parts[:3]\n",
    "    return [0, 0, 0]\n",
    "\n",
    "# Parse formation columns\n",
    "grouped_data[['defenders', 'midfielders', 'forwards']] = pd.DataFrame(\n",
    "    grouped_data['formation'].apply(parse_formation).tolist(), index=grouped_data.index)\n",
    "grouped_data[['defenders_opp', 'midfielders_opp', 'forwards_opp']] = pd.DataFrame(\n",
    "    grouped_data['opp formation'].apply(parse_formation).tolist(), index=grouped_data.index)\n",
    "\n",
    "# Drop original formation columns\n",
    "grouped_data = grouped_data.drop(columns=['formation', 'opp formation'])\n",
    "grouped_data=grouped_data.fillna(0)\n",
    "# Add Opponent Strength Data\n",
    "team_data = pd.DataFrame({\n",
    "    'opponent': [\n",
    "        'Arsenal', 'Aston Villa', 'Bournemouth', 'Brentford', 'Brighton',\n",
    "        'Burnley', 'Chelsea', 'Crystal Palace', 'Everton', 'Fulham',\n",
    "        'Liverpool', 'Luton Town', 'Manchester Utd', 'Newcastle Utd',\n",
    "        \"Nott'ham Forest\", 'Sheffield Utd', 'Tottenham', 'West Ham', 'Wolves'\n",
    "    ],\n",
    "    'opponent_strength': [\n",
    "        4.07, 0.57, -0.48, -0.02, -0.21, -0.79, 0.88, -0.18, -0.10, -0.40,\n",
    "        3.45, -0.90, -0.29, 0.96, -0.44, -1.03, 0.71, -0.51, -0.54\n",
    "    ],\n",
    "})\n",
    "\n",
    "grouped_data = pd.merge(grouped_data, team_data, on='opponent', how='left')\n",
    "\n",
    "# Save the processed data\n",
    "output_file_path = '../data/model/processed_xg_rolling_features_enhanced.csv'\n",
    "grouped_data.to_csv(output_file_path, index=False)\n",
    "print(f\"Processed data saved to {output_file_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ../data/model/processed_xg_rolling_features_enhanced.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T02:49:20.482004Z",
     "start_time": "2025-02-14T02:49:04.502102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Paths to the data\n",
    "haaland_features_path = '../data/model/enhanced_haaland_match_features.csv'\n",
    "xg_features_path = '../data/model/processed_xg_rolling_features_enhanced.csv'\n",
    "\n",
    "# Load datasets\n",
    "haaland_features = pd.read_csv(haaland_features_path)\n",
    "xg_features = pd.read_csv(xg_features_path)\n",
    "\n",
    "# Standardize column names to lowercase\n",
    "haaland_features.columns = haaland_features.columns.str.strip().str.lower()\n",
    "xg_features.columns = xg_features.columns.str.strip().str.lower()\n",
    "\n",
    "# Ensure 'round' column is consistent\n",
    "xg_features['round'] = xg_features['round'].astype(int)\n",
    "haaland_features['round'] = haaland_features['round'].astype(int)\n",
    "\n",
    "# Merge datasets on 'round', using left join\n",
    "merged_data = xg_features\n",
    "\n",
    "# Filter for rounds less than 33\n",
    "filtered_data = merged_data[merged_data['round']]\n",
    "\n",
    "# Define feature columns for prediction\n",
    "xg_features_only = [\n",
    "    'rolling_expected goals', 'cumulative_expected goals',\n",
    "    'rolling_goals', 'cumulative_goals', 'rolling_shots', 'cumulative_shots',\n",
    "    'rolling_touches', 'cumulative_touches', 'rolling_poss', 'cumulative_poss',\n",
    "    'rolling_gca', 'cumulative_gca', 'rolling_sca', 'cumulative_sca',\n",
    "    'rolling_haaland_gls', 'cumulative_haaland_gls',\n",
    "    'rolling_haaland_ast', 'cumulative_haaland_ast',\n",
    "    'rolling_haaland_sh', 'cumulative_haaland_sh',\n",
    "    'rolling_haaland_min', 'cumulative_haaland_min',\n",
    "    'rolling_haaland_touches', 'cumulative_haaland_touches',\n",
    "    'rolling_haaland_poss', 'cumulative_haaland_poss',\n",
    "    'rolling_haaland_gca', 'cumulative_haaland_gca',\n",
    "    'rolling_haaland_sca', 'cumulative_haaland_sca',\n",
    "    'haaland_performance_rating', 'rolling_haaland_rating', 'cumulative_haaland_rating',\n",
    "    'defenders', 'midfielders', 'forwards',\n",
    "    'defenders_opp', 'midfielders_opp', 'forwards_opp', 'opponent_strength','min'\n",
    "]\n",
    "\n",
    "# Ensure all required features are present in the filtered dataset\n",
    "X = filtered_data[xg_features_only].dropna()  # Remove rows with missing values\n",
    "y = filtered_data.loc[X.index, 'expected goals']  # Match rows for 'expected goals'\n",
    "\n",
    "# Compute feature importance using RandomForestRegressor (you can use any model)\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Normalize feature importances to get feature weights (can scale by any factor)\n",
    "feature_weights = feature_importance / feature_importance.sum()\n",
    "\n",
    "# Create a DataFrame for feature importance and weights\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': xg_features_only,\n",
    "    'Importance': feature_importance,\n",
    "    'Weight': feature_weights\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Save the feature importance to CSV\n",
    "feature_importance_path = '../data/model/feature_importance.csv'\n",
    "feature_importance_df.to_csv(feature_importance_path, index=False)\n",
    "\n",
    "# Print feature importance\n",
    "print(\"Feature Importance and Weights:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Scale the features based on the importance\n",
    "X_scaled = X.copy()\n",
    "for i, feature in enumerate(xg_features_only):\n",
    "    X_scaled[feature] = X[feature] * feature_weights[i]\n",
    "\n",
    "# Train a Gradient Boosting Regressor with the scaled features\n",
    "gb_model = GradientBoostingRegressor(random_state=42, n_estimators=100)\n",
    "gb_model.fit(X_scaled, y)\n",
    "\n",
    "# Predict on the same data\n",
    "y_pred = gb_model.predict(X_scaled)\n",
    "\n",
    "# Evaluate model performance on the same data\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Model Evaluation Metrics (with Gradient Boosting and Feature Scaling):\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)\n"
   ],
   "id": "7760d10441312fc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance and Weights:\n",
      "                       Feature  Importance    Weight\n",
      "30  haaland_performance_rating    0.251792  0.251792\n",
      "37             midfielders_opp    0.066260  0.066260\n",
      "21      cumulative_haaland_min    0.053377  0.053377\n",
      "0       rolling_expected goals    0.050219  0.050219\n",
      "39           opponent_strength    0.047445  0.047445\n",
      "1    cumulative_expected goals    0.044544  0.044544\n",
      "29      cumulative_haaland_sca    0.042089  0.042089\n",
      "3             cumulative_goals    0.040751  0.040751\n",
      "13              cumulative_sca    0.037124  0.037124\n",
      "20         rolling_haaland_min    0.034078  0.034078\n",
      "17      cumulative_haaland_ast    0.030294  0.030294\n",
      "7           cumulative_touches    0.026661  0.026661\n",
      "22     rolling_haaland_touches    0.023987  0.023987\n",
      "31      rolling_haaland_rating    0.019231  0.019231\n",
      "6              rolling_touches    0.018505  0.018505\n",
      "28         rolling_haaland_sca    0.018072  0.018072\n",
      "19       cumulative_haaland_sh    0.017533  0.017533\n",
      "4                rolling_shots    0.013978  0.013978\n",
      "40                         min    0.013730  0.013730\n",
      "25     cumulative_haaland_poss    0.013460  0.013460\n",
      "12                 rolling_sca    0.013397  0.013397\n",
      "23  cumulative_haaland_touches    0.013322  0.013322\n",
      "5             cumulative_shots    0.011320  0.011320\n",
      "27      cumulative_haaland_gca    0.011160  0.011160\n",
      "18          rolling_haaland_sh    0.010472  0.010472\n",
      "10                 rolling_gca    0.009730  0.009730\n",
      "15      cumulative_haaland_gls    0.007282  0.007282\n",
      "34                 midfielders    0.006856  0.006856\n",
      "2                rolling_goals    0.006822  0.006822\n",
      "32   cumulative_haaland_rating    0.005780  0.005780\n",
      "11              cumulative_gca    0.005724  0.005724\n",
      "33                   defenders    0.005644  0.005644\n",
      "14         rolling_haaland_gls    0.005484  0.005484\n",
      "9              cumulative_poss    0.005267  0.005267\n",
      "8                 rolling_poss    0.004609  0.004609\n",
      "38                forwards_opp    0.003644  0.003644\n",
      "24        rolling_haaland_poss    0.003569  0.003569\n",
      "36               defenders_opp    0.002866  0.002866\n",
      "26         rolling_haaland_gca    0.002789  0.002789\n",
      "35                    forwards    0.000808  0.000808\n",
      "16         rolling_haaland_ast    0.000328  0.000328\n",
      "Model Evaluation Metrics (with Gradient Boosting and Feature Scaling):\n",
      "Mean Squared Error (MSE): 4.501078735988708e-06\n",
      "Mean Absolute Error (MAE): 0.0018199012106017614\n",
      "R² Score: 0.9999944407460245\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T02:49:31.220670Z",
     "start_time": "2025-02-14T02:49:31.211581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_and_compare_expected_goals(venue, opponent, min, model, xg_features, xg_features_only):\n",
    "    \"\"\"\n",
    "    Compares the actual Expected Goals in the filtered data with the predicted Expected Goals.\n",
    "    \n",
    "    Parameters:\n",
    "    - venue: Venue of the match\n",
    "    - opponent: Opponent team\n",
    "    - min: Additional minutes to include in the prediction\n",
    "    - model: The pre-trained prediction model (e.g., GradientBoostingRegressor)\n",
    "    - xg_features: The dataset used for making predictions\n",
    "    - xg_features_only: List of features used for prediction\n",
    "    \n",
    "    Returns:\n",
    "    - Comparison of actual and predicted Expected Goals\n",
    "    \"\"\"\n",
    "    # Filter the data for the specified venue and opponent\n",
    "    filtered_data = xg_features[(xg_features['venue'] == venue) & \n",
    "                                (xg_features['opponent'] == opponent)].copy()  # Use a copy to avoid modifying the original\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        return \"No matching data for the specified venue and opponent.\"\n",
    "    \n",
    "    # Update the 'Min' feature for prediction\n",
    "    filtered_data['min'] = min\n",
    "    \n",
    "    # Print the updated 'min' values to verify\n",
    "    print(filtered_data['min'].tolist())\n",
    "    \n",
    "    # Extract actual Expected Goals\n",
    "    actual_expected_goals = filtered_data['expected goals'].tolist()\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    features = filtered_data[xg_features_only]\n",
    "\n",
    "    # Use the model to predict Expected Goals\n",
    "    predicted_expected_goals = model.predict(features)\n",
    "\n",
    "    # Create a comparison dataframe\n",
    "    comparison = pd.DataFrame({\n",
    "        'Actual Expected Goals': actual_expected_goals,\n",
    "        'Predicted Expected Goals': predicted_expected_goals\n",
    "    })\n",
    "\n",
    "    # Return the comparison\n",
    "    return comparison\n"
   ],
   "id": "201f993f323af401",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T02:49:32.918627Z",
     "start_time": "2025-02-14T02:49:32.899370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Bundle the model and preprocessor\n",
    "model_preprocessor_bundle = {\n",
    "    'model': gb_model,\n",
    "    \n",
    "}\n",
    "\n",
    "# Save to a pickle file\n",
    "file_path = '../data/model/gb_model.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_preprocessor_bundle, file)\n",
    "\n",
    "print(f\"Model and preprocessor saved to {file_path}\")\n"
   ],
   "id": "a06e2a05761da7fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessor saved to ../data/model/gb_model.pkl\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T02:51:31.118219Z",
     "start_time": "2025-02-14T02:51:31.099246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "# Assuming you have the trained model and data ready\n",
    "xg_features_only = [\n",
    "    'rolling_expected goals', 'cumulative_expected goals',\n",
    "    'rolling_goals', 'cumulative_goals', 'rolling_shots', 'cumulative_shots',\n",
    "    'rolling_touches', 'cumulative_touches', 'rolling_poss', 'cumulative_poss',\n",
    "    'rolling_gca', 'cumulative_gca', 'rolling_sca', 'cumulative_sca',\n",
    "    'rolling_haaland_gls', 'cumulative_haaland_gls',\n",
    "    'rolling_haaland_ast', 'cumulative_haaland_ast',\n",
    "    'rolling_haaland_sh', 'cumulative_haaland_sh',\n",
    "    'rolling_haaland_min', 'cumulative_haaland_min',\n",
    "    'rolling_haaland_touches', 'cumulative_haaland_touches',\n",
    "    'rolling_haaland_poss', 'cumulative_haaland_poss',\n",
    "    'rolling_haaland_gca', 'cumulative_haaland_gca',\n",
    "    'rolling_haaland_sca', 'cumulative_haaland_sca',\n",
    "    'haaland_performance_rating', 'rolling_haaland_rating', 'cumulative_haaland_rating',\n",
    "    'defenders', 'midfielders', 'forwards',\n",
    "    'defenders_opp', 'midfielders_opp', 'forwards_opp', 'opponent_strength','min'\n",
    "]\n",
    "xg_features = pd.read_csv(xg_features_path)\n",
    "xg_features.columns = xg_features.columns.str.strip().str.lower()\n",
    "\n",
    "# Ensure 'round' column is consistent\n",
    "xg_features['round'] = xg_features['round'].astype(int)\n",
    "\n",
    "comparison_result = predict_and_compare_expected_goals('Home', \"Luton Town\", 90, gb_model, xg_features, xg_features_only)\n",
    "\n",
    "# Display the comparison result\n",
    "print(comparison_result)\n"
   ],
   "id": "58e72939a7c4adea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\n",
      "   Actual Expected Goals  Predicted Expected Goals\n",
      "0                    4.2                  2.805339\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9cbbdd47a76c4c26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
